{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 数据文件简介\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 hdf5 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "f=h5py.File(\"tmp/tmp1.hdf5\",'w')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->key 0 = dset1 <---\n",
      "f[key].name= /dset1\n",
      "f[key].shape= (20,)\n",
      "f[key].value= [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"tmp/tmp1.hdf5\",'w') as f:\n",
    "    # `dset1` 是数据集的 name, `(20,)` 是数据集的 shape, `i` 是数据集的元素类型\n",
    "    d1=f.create_dataset(\"dset1\",(20,),\"i\")\n",
    "\n",
    "    for i,key in enumerate(f.keys()):\n",
    "        print(\"--->key\",i,\"=\",key,\"<---\")\n",
    "        print(\"f[key].name=\",f[key].name)\n",
    "        print(\"f[key].shape=\",f[key].shape)\n",
    "        print(\"f[key].value=\",f[key][:])    # 数据集的输出是个 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->key0=dset2<---\n",
      "dset2 is Dataset!\n",
      "f[dset2].shape=(15,)\n",
      "f[dset2].values=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "dset2: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "--->key1=dset3<---\n",
      "dset3 is Dataset!\n",
      "f[dset3].shape=(20,)\n",
      "f[dset3].values=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "dset3: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "--->value0=<HDF5 dataset \"dset2\": shape (15,), type \"<i4\"><---\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "--->value1=<HDF5 dataset \"dset3\": shape (20,), type \"<i4\"><---\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"tmp/tmp4.hdf5\",'w') as f:\n",
    "    d1=np.arange(20)    # 赋值方法1\n",
    "    f[\"dset2\"]=np.arange(15)    # 赋值方法2\n",
    "    a=np.arange(20)\n",
    "    d3=f.create_dataset(\"dset3\",data=a) # 赋值方法3\n",
    "\n",
    "    for i,key in enumerate(f.keys()):\n",
    "        print(\"--->key{0}={1}<---\".format(i,key))\n",
    "        if type(f[key])==h5py.Dataset:\n",
    "            print(\"{} is Dataset!\".format(key))\n",
    "        if isinstance(f[key],h5py.Dataset):\n",
    "            print(\"f[{}].shape={}\".format(key,f[key].shape))\n",
    "            print(\"f[{}].values={}\".format(key,f[key][:]))\n",
    "            print(\"%s: %s\" %(key, f[key][:]))\n",
    "            pass\n",
    "\n",
    "    for i,values in enumerate(f.values()):\n",
    "        print(\"--->value{0}={1}<---\".format(i,values))\n",
    "        if isinstance(values,h5py.Dataset):\n",
    "            print([value for value in values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建组（Group）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "f.name= /\n",
      "==========\n",
      "f下的项目\n",
      "--->key0=bar1<---\n",
      "f[bar1].name=/bar1\n",
      "f[bar1].len=2\n",
      "--->key1=bar2<---\n",
      "f[bar2].name=/bar2\n",
      "f[bar2].len=3\n",
      "--->key2=dset<---\n",
      "f[dset].name=/dset\n",
      "f[dset].len=10\n",
      "f[dset].values=[0 1 2 3 4 5 6 7 8 9]\n",
      "==========\n",
      "bar1下的项目\n",
      "--->key0=car1<---\n",
      "f[car1].name=/bar1/car1\n",
      "f[car1].attrs=<Attributes of HDF5 object at 2576766960744>\n",
      "--->key1=dset1<---\n",
      "f[dset1].name=/bar1/dset1\n",
      "f[dset1].attrs=<Attributes of HDF5 object at 2576766281000>\n",
      "==========\n",
      "car1下的项目：没有输出\n",
      "c1.keys()= []\n",
      "==========\n",
      "遍历文件中的所有项目\n",
      "bar1\n",
      "bar1/car1\n",
      "bar1/dset1\n",
      "bar2\n",
      "bar2/car2\n",
      "bar2/car3\n",
      "bar2/dset2\n",
      "dset\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"tmp/tmp5.hdf5\",\"w\") as f:\n",
    "    # 创建组 `bar1`, 创建组 `bar2`, 数据集 `dset`\n",
    "    g1=f.create_group('bar1')\n",
    "    g2=f.create_group('bar2')\n",
    "    d=f.create_dataset('dset',data=np.arange(10))\n",
    "\n",
    "    # 在 `bar1` 组里面创建组 `car1` 和 数据集 `dset1`\n",
    "    c1=g1.create_group('car1')\n",
    "    d1=g1.create_dataset('dset1',data=np.arange(20))\n",
    "\n",
    "    # 在 `bar2` 组里面创建组 `car2` 和 数据集 `dset2`\n",
    "    c2=g2.create_group('car2')\n",
    "    c2=g2.create_group('car3')\n",
    "    d2=g2.create_dataset('dset2',data=np.arange(20))\n",
    "\n",
    "    print('='*10)\n",
    "    print(\"f.name=\",f.name)\n",
    "    \n",
    "    print('='*10)\n",
    "    print(\"f下的项目\")\n",
    "    for i,key in enumerate(f.keys()):\n",
    "        print(\"--->key{0}={1}<---\".format(i,key))\n",
    "        print(\"f[{}].name={}\".format(key,f[key].name))\n",
    "        print(\"f[{}].len={}\".format(key,len(f[key])))\n",
    "        if type(f[key])==h5py.Dataset:\n",
    "            print(\"f[{}].values={}\".format(key,f[key][:]))\n",
    "        pass\n",
    "    \n",
    "    # 输出 `bar1` 下的 组和数据集\n",
    "    print('='*10)\n",
    "    print(\"bar1下的项目\")\n",
    "    for i,key in enumerate(g1.keys()):\n",
    "        print(\"--->key{0}={1}<---\".format(i,key))\n",
    "        print(\"f[{}].name={}\".format(key,g1[key].name))\n",
    "        print(\"f[{}].attrs={}\".format(key,g1[key].attrs))\n",
    "        pass\n",
    "\n",
    "    # 输出 `car1` 下的 组和数据集\n",
    "    print('='*10)\n",
    "    print(\"car1下的项目：没有输出\")\n",
    "    print(\"c1.keys()=\",[key for key in c1.keys()])\n",
    "    for i,key in enumerate(c1.keys()):\n",
    "        print(\"--->key{0}={1}<---\".format(i,key))\n",
    "        print(\"f[{}].name={}\".format(key,c1[key].name))\n",
    "        pass\n",
    "\n",
    "    # 遍历文件中的所有项目\n",
    "    print('='*10)\n",
    "    print(\"遍历文件中的所有项目\")\n",
    "    f.visit(lambda item: print(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1b8236355cd48af21de644c7b16cb5da37a47bcd5566053d684b48a58b5ab16"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pix2pix': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
